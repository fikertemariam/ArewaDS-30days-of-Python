{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a9d6daf",
   "metadata": {},
   "source": [
    "# Exercises: Day 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f27fbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.Read this url and find the 10 most frequent words. romeo_and_juliet = 'http://www.gutenberg.org/files/1112/1112.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68c84c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89069fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unable to retrieve content from the URL. Status code: 404\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "\n",
    "# URL of the text\n",
    "romeo_and_juliet_url = 'http://www.gutenberg.org/files/1112/1112.txt'\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(romeo_and_juliet_url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Extract text from the HTML content\n",
    "    text = soup.get_text()\n",
    "\n",
    "    # Tokenize the text into words\n",
    "    words = text.split()\n",
    "\n",
    "    # Count the occurrences of each word\n",
    "    word_counts = Counter(words)\n",
    "\n",
    "    # Get the 10 most common words\n",
    "    most_common_words = word_counts.most_common(10)\n",
    "\n",
    "    # Print the result\n",
    "    print(most_common_words)\n",
    "\n",
    "else:\n",
    "    print(f\"Error: Unable to retrieve content from the URL. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b657461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.Read the cats API and cats_api = 'https://api.thecatapi.com/v1/breeds' and find :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5c8c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#i.the min, max, mean, median, standard deviation of cats' weight in metric units.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b36cffe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4274339a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Weight: 2.0 kg\n",
      "Maximum Weight: 5.0 kg\n",
      "Mean Weight: 3.2238805970149254 kg\n",
      "Median Weight: 3.0 kg\n",
      "Standard Deviation of Weight: 0.8845628182703051 kg\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import statistics\n",
    "\n",
    "# URL of the cats API\n",
    "cats_api = 'https://api.thecatapi.com/v1/breeds'\n",
    "\n",
    "# Send a GET request to the API\n",
    "response = requests.get(cats_api)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Get the JSON data from the response\n",
    "    cat_data = response.json()\n",
    "\n",
    "    # Extract weights in metric units and convert to a list of floats\n",
    "    weights = [float(cat.get('weight', {}).get('metric', '').split()[0]) for cat in cat_data]\n",
    "\n",
    "    # Calculate statistics\n",
    "    min_weight = min(weights)\n",
    "    max_weight = max(weights)\n",
    "    mean_weight = statistics.mean(weights)\n",
    "    median_weight = statistics.median(weights)\n",
    "    std_dev_weight = statistics.stdev(weights)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Minimum Weight: {min_weight} kg\")\n",
    "    print(f\"Maximum Weight: {max_weight} kg\")\n",
    "    print(f\"Mean Weight: {mean_weight} kg\")\n",
    "    print(f\"Median Weight: {median_weight} kg\")\n",
    "    print(f\"Standard Deviation of Weight: {std_dev_weight} kg\")\n",
    "\n",
    "else:\n",
    "    print(f\"Error: Unable to retrieve data from the cats API. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0125e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Lifespan: 8.0 years\n",
      "Maximum Lifespan: 18.0 years\n",
      "Mean Lifespan: 12.074626865671641 years\n",
      "Median Lifespan: 12.0 years\n",
      "Standard Deviation of Lifespan: 1.8283411328456127 years\n"
     ]
    }
   ],
   "source": [
    "#ii.the min, max, mean, median, standard deviation of cats' lifespan in years.\n",
    "import requests\n",
    "import statistics\n",
    "\n",
    "# URL of the cats API\n",
    "cats_api = 'https://api.thecatapi.com/v1/breeds'\n",
    "\n",
    "# Send a GET request to the API\n",
    "response = requests.get(cats_api)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Get the JSON data from the response\n",
    "    cat_data = response.json()\n",
    "\n",
    "    # Extract lifespan in years and convert to a list of floats\n",
    "    lifespans = [float(cat.get('life_span', '').split()[0]) for cat in cat_data if cat.get('life_span', '')]\n",
    "\n",
    "    # Calculate statistics\n",
    "    min_lifespan = min(lifespans)\n",
    "    max_lifespan = max(lifespans)\n",
    "    mean_lifespan = statistics.mean(lifespans)\n",
    "    median_lifespan = statistics.median(lifespans)\n",
    "    std_dev_lifespan = statistics.stdev(lifespans)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Minimum Lifespan: {min_lifespan} years\")\n",
    "    print(f\"Maximum Lifespan: {max_lifespan} years\")\n",
    "    print(f\"Mean Lifespan: {mean_lifespan} years\")\n",
    "    print(f\"Median Lifespan: {median_lifespan} years\")\n",
    "    print(f\"Standard Deviation of Lifespan: {std_dev_lifespan} years\")\n",
    "\n",
    "else:\n",
    "    print(f\"Error: Unable to retrieve data from the cats API. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef745050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency Table of Country and Breed of Cats:\n",
      "Country              Breed                          Frequency \n",
      "============================================================\n",
      "Egypt                Abyssinian                     1         \n",
      "Greece               Aegean                         1         \n",
      "United States        American Bobtail               1         \n",
      "United States        American Curl                  1         \n",
      "United States        American Shorthair             1         \n",
      "United States        American Wirehair              1         \n",
      "United Arab Emirates Arabian Mau                    1         \n",
      "Australia            Australian Mist                1         \n",
      "United States        Balinese                       1         \n",
      "United States        Bambino                        1         \n",
      "United States        Bengal                         1         \n",
      "France               Birman                         1         \n",
      "United States        Bombay                         1         \n",
      "United Kingdom       British Longhair               1         \n",
      "United Kingdom       British Shorthair              1         \n",
      "Burma                Burmese                        1         \n",
      "United Kingdom       Burmilla                       1         \n",
      "United States        California Spangled            1         \n",
      "United States        Chantilly-Tiffany              1         \n",
      "France               Chartreux                      1         \n",
      "Egypt                Chausie                        1         \n",
      "United States        Cheetoh                        1         \n",
      "United States        Colorpoint Shorthair           1         \n",
      "United Kingdom       Cornish Rex                    1         \n",
      "Canada               Cymric                         1         \n",
      "Cyprus               Cyprus                         1         \n",
      "United Kingdom       Devon Rex                      1         \n",
      "Russia               Donskoy                        1         \n",
      "China                Dragon Li                      1         \n",
      "Egypt                Egyptian Mau                   1         \n",
      "Burma                European Burmese               1         \n",
      "United States        Exotic Shorthair               1         \n",
      "United Kingdom       Havana Brown                   1         \n",
      "United States        Himalayan                      1         \n",
      "Japan                Japanese Bobtail               1         \n",
      "United States        Javanese                       1         \n",
      "Thailand             Khao Manee                     1         \n",
      "Thailand             Korat                          1         \n",
      "Russia               Kurilian                       1         \n",
      "Thailand             LaPerm                         1         \n",
      "United States        Maine Coon                     1         \n",
      "United Kingdom       Malayan                        1         \n",
      "Isle of Man          Manx                           1         \n",
      "United States        Munchkin                       1         \n",
      "United States        Nebelung                       1         \n",
      "Norway               Norwegian Forest Cat           1         \n",
      "United States        Ocicat                         1         \n",
      "United States        Oriental                       1         \n",
      "Iran (Persia)        Persian                        1         \n",
      "United States        Pixie-bob                      1         \n",
      "United States        Ragamuffin                     1         \n",
      "United States        Ragdoll                        1         \n",
      "Russia               Russian Blue                   1         \n",
      "United States        Savannah                       1         \n",
      "United Kingdom       Scottish Fold                  1         \n",
      "United States        Selkirk Rex                    1         \n",
      "Thailand             Siamese                        1         \n",
      "Russia               Siberian                       1         \n",
      "Singapore            Singapura                      1         \n",
      "United States        Snowshoe                       1         \n",
      "Somalia              Somali                         1         \n",
      "Canada               Sphynx                         1         \n",
      "Canada               Tonkinese                      1         \n",
      "United States        Toyger                         1         \n",
      "Turkey               Turkish Angora                 1         \n",
      "Turkey               Turkish Van                    1         \n",
      "United States        York Chocolate                 1         \n"
     ]
    }
   ],
   "source": [
    "#iii.Create a frequency table of country and breed of cats\n",
    "import requests\n",
    "from collections import Counter\n",
    "\n",
    "# URL of the cats API\n",
    "cats_api = 'https://api.thecatapi.com/v1/breeds'\n",
    "\n",
    "# Send a GET request to the API\n",
    "response = requests.get(cats_api)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Get the JSON data from the response\n",
    "    cat_data = response.json()\n",
    "\n",
    "    # Extract country and breed information and create a frequency table\n",
    "    country_breed_freq = Counter((cat.get('origin', ''), cat.get('name', '')) for cat in cat_data)\n",
    "\n",
    "    # Print the frequency table\n",
    "    print(\"Frequency Table of Country and Breed of Cats:\")\n",
    "    print(\"{:<20} {:<30} {:<10}\".format(\"Country\", \"Breed\", \"Frequency\"))\n",
    "    print(\"=\"*60)\n",
    "    for (country, breed), frequency in country_breed_freq.items():\n",
    "        print(\"{:<20} {:<30} {:<10}\".format(country, breed, frequency))\n",
    "\n",
    "else:\n",
    "    print(f\"Error: Unable to retrieve data from the cats API. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45375b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.Read the countries API and find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "523e6661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Largest Countries:\n",
      "Rank Country                                  Total Area (sq km)\n",
      "============================================================\n",
      "1   Russian Federation                       17124442.0     \n",
      "2   Antarctica                               14000000.0     \n",
      "3   Canada                                   9984670.0      \n",
      "4   China                                    9640011.0      \n",
      "5   United States of America                 9629091.0      \n",
      "6   Brazil                                   8515767.0      \n",
      "7   Australia                                7692024.0      \n",
      "8   India                                    3287590.0      \n",
      "9   Argentina                                2780400.0      \n",
      "10  Kazakhstan                               2724900.0      \n"
     ]
    }
   ],
   "source": [
    "#i.the 10 largest countries\n",
    "\n",
    "import requests\n",
    "\n",
    "# URL of the countries API\n",
    "countries_api = 'https://restcountries.com/v2/all'\n",
    "\n",
    "# Send a GET request to the API\n",
    "response = requests.get(countries_api)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Get the JSON data from the response\n",
    "    countries_data = response.json()\n",
    "\n",
    "    # Sort countries based on total area in descending order\n",
    "    sorted_countries = sorted(countries_data, key=lambda x: x.get('area', 0), reverse=True)\n",
    "\n",
    "    # Get the top 10 largest countries\n",
    "    top_10_largest_countries = sorted_countries[:10]\n",
    "\n",
    "    # Print the list of 10 largest countries\n",
    "    print(\"Top 10 Largest Countries:\")\n",
    "    print(\"{:<3} {:<40} {:<15}\".format(\"Rank\", \"Country\", \"Total Area (sq km)\"))\n",
    "    print(\"=\"*60)\n",
    "    for i, country in enumerate(top_10_largest_countries, start=1):\n",
    "        country_name = country.get('name', '')\n",
    "        total_area = country.get('area', 0)\n",
    "        print(\"{:<3} {:<40} {:<15}\".format(i, country_name, total_area))\n",
    "\n",
    "else:\n",
    "    print(f\"Error: Unable to retrieve data from the countries API. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06027c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Most Spoken Languages:\n",
      "Rank Language                  Frequency \n",
      "==================================================\n",
      "1   English                   91        \n",
      "2   French                    45        \n",
      "3   Arabic                    25        \n",
      "4   Spanish                   24        \n",
      "5   Portuguese                10        \n",
      "6   Russian                   8         \n",
      "7   Dutch                     8         \n",
      "8   German                    7         \n",
      "9   Chinese                   5         \n",
      "10  Serbian                   4         \n"
     ]
    }
   ],
   "source": [
    "#ii.the 10 most spoken languages\n",
    "import requests\n",
    "\n",
    "# URL of the countries API\n",
    "countries_api = 'https://restcountries.com/v2/all'\n",
    "\n",
    "# Send a GET request to the API\n",
    "response = requests.get(countries_api)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Get the JSON data from the response\n",
    "    countries_data = response.json()\n",
    "\n",
    "    # Extract language names from all countries\n",
    "    all_languages = [language['name'] for country in countries_data for language in country.get('languages', [])]\n",
    "\n",
    "    # Create a frequency table for languages\n",
    "    language_frequency = {}\n",
    "    for language in all_languages:\n",
    "        language_frequency[language] = language_frequency.get(language, 0) + 1\n",
    "\n",
    "    # Sort languages based on frequency in descending order\n",
    "    sorted_languages = sorted(language_frequency.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the top 10 most spoken languages\n",
    "    top_10_languages = sorted_languages[:10]\n",
    "\n",
    "    # Print the list of 10 most spoken languages\n",
    "    print(\"Top 10 Most Spoken Languages:\")\n",
    "    print(\"{:<3} {:<25} {:<10}\".format(\"Rank\", \"Language\", \"Frequency\"))\n",
    "    print(\"=\"*50)\n",
    "    for i, (language, frequency) in enumerate(top_10_languages, start=1):\n",
    "        print(\"{:<3} {:<25} {:<10}\".format(i, language, frequency))\n",
    "\n",
    "else:\n",
    "    print(f\"Error: Unable to retrieve data from the countries API. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f84632ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of languages in the countries API: 112\n"
     ]
    }
   ],
   "source": [
    "#iii.the total number of languages in the countries API\n",
    "import requests\n",
    "\n",
    "# URL of the countries API\n",
    "countries_api = 'https://restcountries.com/v2/all'\n",
    "\n",
    "# Send a GET request to the API\n",
    "response = requests.get(countries_api)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Get the JSON data from the response\n",
    "    countries_data = response.json()\n",
    "\n",
    "    # Extract language codes from all countries\n",
    "    all_languages = [language.get('iso639_1', None) for country in countries_data for language in country.get('languages', [])]\n",
    "\n",
    "    # Remove None values\n",
    "    all_languages = [lang for lang in all_languages if lang is not None]\n",
    "\n",
    "    # Get the total number of unique languages\n",
    "    total_languages = len(set(all_languages))\n",
    "\n",
    "    print(f\"Total number of languages in the countries API: {total_languages}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Error: Unable to retrieve data from the countries API. Status code: {response.status_code}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecafc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.UCI is one of the most common places to get data sets for data science and machine learning. Read the content of UCL (https://archive.ics.uci.edu/ml/datasets.php). Without additional libraries it will be difficult, so you may try it with BeautifulSoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cbb9161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No tables found on the page.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of UCI Machine Learning Repository\n",
    "uci_url = 'https://archive.ics.uci.edu/datasets'\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(uci_url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find all tables on the page\n",
    "    all_tables = soup.find_all('table')\n",
    "\n",
    "    # Assume the first table contains dataset information\n",
    "    if all_tables:\n",
    "        dataset_table = all_tables[0]\n",
    "\n",
    "        # Extract dataset information from the table\n",
    "        datasets = []\n",
    "        for row in dataset_table.find_all('tr')[1:]:  # Skip the header row\n",
    "            columns = row.find_all('td')\n",
    "            dataset_name = columns[0].text.strip()\n",
    "            dataset_type = columns[1].text.strip()\n",
    "            dataset_task = columns[2].text.strip()\n",
    "            datasets.append({'Name': dataset_name, 'Type': dataset_type, 'Task': dataset_task})\n",
    "\n",
    "        # Display the extracted dataset information\n",
    "        for dataset in datasets:\n",
    "            print(f\"Name: {dataset['Name']}\\nType: {dataset['Type']}\\nTask: {dataset['Task']}\\n{'-'*30}\")\n",
    "    else:\n",
    "        print(\"Error: No tables found on the page.\")\n",
    "\n",
    "else:\n",
    "    print(f\"Error: Unable to retrieve data from UCI Machine Learning Repository. Status code: {response.status_code}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdfa51f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
